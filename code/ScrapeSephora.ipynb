{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Objective:** <br>\n",
    "Gather data on skincare products from Sephora for product analysis. <br>\n",
    "\n",
    "#### **Method:** <br>\n",
    "1. Retrieve the URLs of all skincare products.\n",
    "2. Store each product's webpage as an HTML file.\n",
    "3. Gather details about each individual product.\n",
    "4. Export the product information into a CSV file.\n",
    "\n",
    "#### **Summary:** <br>\n",
    "When the skincare product links were obtained, there are 2894 skincare products on Sephora. However, information for only 2560 products could be obtained due to the following reasons:<br> 1. Some products have been removed from the website and are no longer accessible. <br> 2. Critical product information could not be extracted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libaries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from requests.exceptions import ReadTimeout\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Section 1. Define Functions to Extract Product Information** <br>\n",
    "Retrieve information about: <br>\n",
    " * product's hierarcy, \n",
    " * brand, \n",
    " * product name, \n",
    " * product rating, \n",
    " * number of love count, \n",
    " * number of reviews, \n",
    " * skin concern, \n",
    " * skin type, \n",
    " * item number, \n",
    " * similar items, \n",
    " * different item variations  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get skincare hierarchy of each product such as: Skincare > Cleansers > Face Wash & Cleansers\n",
    "def get_product_breadcrumbs(json_dict):\n",
    "    try:\n",
    "        product_info = json_dict[\"page\"][\"product\"]\n",
    "        breadcrumbs_json = product_info.get(\"breadcrumbsSeoJsonLd\")\n",
    "        if breadcrumbs_json:\n",
    "            return [x[\"item\"][\"name\"] for x in json.loads(breadcrumbs_json)[\"itemListElement\"]]\n",
    "        else:\n",
    "            return None\n",
    "    except KeyError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the brand of the product\n",
    "def get_brand(json_dict):\n",
    "    return json_dict[\"page\"][\"product\"][\"productDetails\"]['brand'].get('displayName', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get product name\n",
    "def get_product_name(json_dict):\n",
    "    return json_dict[\"page\"][\"product\"][\"productDetails\"].get('displayName', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get product rating\n",
    "def get_rating(json_dict):\n",
    "    return json_dict[\"page\"][\"product\"][\"productDetails\"].get('rating', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of times consumers loved this product\n",
    "def get_lovesCount(json_dict):\n",
    "    return json_dict[\"page\"][\"product\"][\"productDetails\"].get('lovesCount', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of reviews\n",
    "def get_review_num(json_dict):\n",
    "    return json_dict[\"page\"][\"product\"][\"productDetails\"].get('reviews', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the skin type the product is suitable for\n",
    "def get_skin_type(json_dict):\n",
    "    skin_type_results = json_dict[\"page\"][\"product\"][\"productDetails\"].get('longDescription', None)\n",
    "    if skin_type_results is not None:\n",
    "        product_soup = BeautifulSoup(skin_type_results, 'html.parser')\n",
    "\n",
    "        skin_type_tag = product_soup.find('b', string='Skin Type:')\n",
    "        if skin_type_tag is not None: \n",
    "            next_sibling = skin_type_tag.next_sibling\n",
    "            try:\n",
    "                if next_sibling is not None:\n",
    "                    skin_type_text = next_sibling.strip()\n",
    "                    return skin_type_text\n",
    "                else:\n",
    "                    return None \n",
    "            except Exception as e:\n",
    "                print(\"Error occurred while processing skin type:\", e)\n",
    "                return None\n",
    "        else:\n",
    "            return None  \n",
    "    else:\n",
    "        return None  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the skincare issue targeted by the product.\n",
    "def get_skin_concern(json_dict):\n",
    "    skin_concern_results = json_dict[\"page\"][\"product\"][\"productDetails\"].get('longDescription', None)\n",
    "    if skin_concern_results is not None:\n",
    "        product_soup = BeautifulSoup(skin_concern_results, 'html.parser')\n",
    "\n",
    "        skin_concern_tag = product_soup.find('b', string='Skincare Concerns:')\n",
    "        if skin_concern_tag is not None: \n",
    "            next_sibling = skin_concern_tag.next_sibling\n",
    "            try:\n",
    "                if next_sibling is not None:\n",
    "                    skin_concern_text = next_sibling.strip()\n",
    "                    return skin_concern_text\n",
    "                else:\n",
    "                    return None \n",
    "            except Exception as e:\n",
    "                print(\"Error occurred while processing skin type:\", e)\n",
    "                return None\n",
    "        else:\n",
    "            return None  \n",
    "    else:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sku of each product. this is the item number on the Sephora webpage\n",
    "def get_sku(json_dict):\n",
    "    return json_dict[\"page\"][\"product\"][\"currentSku\"].get(\"skuId\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the size of each product\n",
    "def get_size(json_dict):\n",
    "    return json_dict[\"page\"][\"product\"][\"currentSku\"].get(\"size\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the product's price (USD)\n",
    "def get_price(json_dict):\n",
    "    price = json_dict[\"page\"][\"product\"][\"currentSku\"].get(\"listPrice\", None)\n",
    "    if price!= None:\n",
    "        price = price[1:]\n",
    "    return price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the product's \"children\", which can be the same product in a different size or different versions of the product (e.g. scent)\n",
    "def get_child_sku(json_dict):\n",
    "    find_child = json_dict[\"page\"][\"product\"].get(\"regularChildSkus\", None)\n",
    "    current_sku = json_dict[\"page\"][\"product\"][\"currentSku\"][\"skuId\"]\n",
    "    child_products = []\n",
    "    if find_child is not None:\n",
    "        for item in find_child:\n",
    "            if item['skuId']!=current_sku:\n",
    "                child_products.append(item['skuId'])\n",
    "    return child_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the product's unique item identifier. This is similar to the sku id \n",
    "def get_item_id(json_dict):\n",
    "    return json_dict['page'][\"product\"][\"productDetails\"].get('productId', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sku_id of similar products \n",
    "def get_similar_products(product_id, headers):\n",
    "    similar_product_url = 'https://sephora.cnstrc.com/recommendations/v1/pods/similar-products-test?c=ciojs-client-2.41.0&key=u7PNVQx-prod-en-us&i=0c7be738-3d64-4f03-b5fd-7c5df9afefdc&s=23&num_results=5&item_id='+product_id\n",
    "    \n",
    "    try:\n",
    "        similar_page = requests.get(similar_product_url, headers=headers, timeout=20)  \n",
    "        similar_page = json.loads(similar_page.text)\n",
    "        \n",
    "        products_list = []\n",
    "        if similar_page[\"response\"].get(\"results\", None) is not None:\n",
    "            for item in similar_page[\"response\"][\"results\"]:\n",
    "                products_list.append(item[\"data\"][\"currentSku\"].get(\"skuId\", None))\n",
    "        else:\n",
    "            products_list.append('')\n",
    "        \n",
    "        return products_list\n",
    "    \n",
    "    except ReadTimeout:\n",
    "        print(f\"Request for product {product_id} timed out. Skipping this product.\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Section 2. Define Functions to Extract Product URLs and Save Product Information** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the product links\n",
    "def get_product_links(url, total_pg, api, headers):\n",
    "    all_products_list = []\n",
    "    for pg in range(1, total_pg+1):\n",
    "        complete_url = url + str(pg)\n",
    "        params = {'api_key':api, 'url':complete_url}\n",
    "\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                page = requests.get('http://api.scraperapi.com', params =urlencode(params), headers=headers)\n",
    "                if page.status_code in [200, 404]:\n",
    "                    break\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                page = ''\n",
    "        \n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(complete_url)\n",
    "\n",
    "        scroll_height = 0\n",
    "        while scroll_height < 10000:\n",
    "            scroll_height += 800\n",
    "            driver.execute_script(f'window.scrollTo(0, {scroll_height});')\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        product_anchors = driver.find_elements(By.CSS_SELECTOR, \".css-klx76\")\n",
    "\n",
    "        product_urls = map(lambda a: a.get_attribute(\"href\"), product_anchors)\n",
    "        product_urls = list(product_urls)\n",
    "        all_products_list = all_products_list + product_urls\n",
    "    \n",
    "    return all_products_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine which product pages are already saved as html files. This will help avoid getting the same data twice.\n",
    "def get_products_saved(folder_path):\n",
    "    dir_list = os.listdir(folder_path)\n",
    "    sku_saved_list = []\n",
    "    for file in dir_list:\n",
    "        sku = re.search(r'\\d+', file).group()\n",
    "        sku_saved_list.append(sku)\n",
    "    return sku_saved_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each product link, save the webpage information into a html file\n",
    "def save_html_info(text_file, saved_sku_pages):\n",
    "\n",
    "    folder_path = 'skincare_products'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    failed_to_load = []\n",
    "    no_sku = []\n",
    "\n",
    "    with open(text_file) as f:\n",
    "        s = f.read()\n",
    "\n",
    "    all_product_urls = s.strip().split('\\n')\n",
    "\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for num, url in enumerate(all_product_urls):\n",
    "        print(num, url)\n",
    "        counter+=1\n",
    "\n",
    "        #get sku_id from url\n",
    "        parsed_url = urlparse(url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        sku_id = query_params.get('skuId')\n",
    "\n",
    "        if len(sku_id)!=0:\n",
    "            sku_id = sku_id[0]\n",
    "            if sku_id in saved_sku_pages:\n",
    "                continue\n",
    "        else:\n",
    "            no_sku.append(url)\n",
    "            continue\n",
    "        \n",
    "        delay = random.uniform(5, 15)\n",
    "        time.sleep(delay) \n",
    "\n",
    "        if counter%500 == 0:\n",
    "            time.sleep(600)\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            file_name = f\"product_{sku_id}.html\"\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            with open(file_path, 'w') as f:\n",
    "                    f.write(driver.page_source)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            failed_to_load.append(url)\n",
    "            continue\n",
    "        \n",
    "    driver.quit()\n",
    "    \n",
    "    return failed_to_load, no_sku\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the skincare information for all products and save the information in a dictionary\n",
    "def get_skincare_info(folder, headers):\n",
    "\n",
    "    skincare_dict ={}\n",
    "    no_page_json_lst = []\n",
    "    \n",
    "    counter = 0\n",
    "    #open the text file and extract information from each link\n",
    "    for html_file in os.listdir(folder):\n",
    "        counter+=1\n",
    "\n",
    "        #get sku_id from url\n",
    "        parsed_url = urlparse(html_file)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        sku_id = query_params.get('skuId')\n",
    "\n",
    "\n",
    "        with open(os.path.join(folder,html_file), 'r') as file:\n",
    "            print(counter, html_file)\n",
    "            html_content = file.read()\n",
    "            product_soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            product_soup = BeautifulSoup(product_soup.prettify(), \"html.parser\")\n",
    "\n",
    "            json_dict = json.loads(product_soup.find(\"script\", {\"id\": \"linkStore\"}).text)\n",
    "\n",
    "            if json_dict[\"page\"].get(\"product\", None) == None:\n",
    "                no_page_json_lst.append(sku_id)\n",
    "                continue\n",
    "            else:\n",
    "                hierarchy = get_product_breadcrumbs(json_dict)\n",
    "                brand = get_brand(json_dict)\n",
    "                product = get_product_name(json_dict)\n",
    "                rating = get_rating(json_dict)\n",
    "                loves_count = get_lovesCount(json_dict)\n",
    "                reviews_num = get_review_num(json_dict)\n",
    "                sku = get_sku(json_dict)\n",
    "                size = get_size(json_dict)\n",
    "                price = get_price(json_dict)\n",
    "                child_sku = get_child_sku(json_dict)\n",
    "                item_id = get_item_id(json_dict)\n",
    "                similar_products = get_similar_products(product_id = item_id, headers =headers )\n",
    "                skin_concern = get_skin_concern(json_dict)\n",
    "                skin_type = get_skin_type(json_dict)\n",
    "\n",
    "                skincare_dict[sku] = {}\n",
    "                if hierarchy!= None:\n",
    "                    skincare_dict[sku]['hierarchy'] = ','.join(hierarchy)\n",
    "                else:\n",
    "                    skincare_dict[sku]['hierarchy'] = None\n",
    "                skincare_dict[sku]['brand'] = brand \n",
    "                skincare_dict[sku]['product'] = product \n",
    "                skincare_dict[sku]['rating'] = rating \n",
    "                skincare_dict[sku]['loves_count'] = loves_count \n",
    "                skincare_dict[sku]['reviews_num'] = reviews_num\n",
    "                skincare_dict[sku]['size'] = size \n",
    "                skincare_dict[sku]['price'] = price \n",
    "                skincare_dict[sku]['child_sku'] = ','.join(child_sku) \n",
    "                skincare_dict[sku]['item_id'] = item_id\n",
    "                skincare_dict[sku]['similar_products'] = ','.join(similar_products)\n",
    "                skincare_dict[sku]['skin_concern'] = skin_concern\n",
    "                skincare_dict[sku]['skin_type'] = skin_type\n",
    "\n",
    "        \n",
    "\n",
    "    return skincare_dict, no_page_json_lst\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Section 3. Function Calls** <br>\n",
    "1. Loop through 49 pages of skincare products to get all the product URLs\n",
    "2. For each URL, open and save the webpage information.  \n",
    "3. Extract information from each html file and save the extracted information as a CSV <br>\n",
    "\n",
    "To access approximately 3000 webpages without being blocked by the website, it's advisable to utilize either an API or proxies. Initially, I opted for an API due to the scarcity of reliable proxies, but I exhausted my free API credits. Consequently, I chose to prolong the interval between each URL request to evade website detection. However, this approach is slower.I saved the product webpage files and conducted scraping in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the skincare URLs from 49 pages\n",
    "headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n",
    "all_product_urls = get_product_links(url= 'https://www.sephora.com/shop/skincare?currentPage=', total_pg =49 , headers = headers, api ='57d761a02ba8a95e8bcad4641873ab9b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all URLs/links to a txt file\n",
    "with open(\"Sephora_URL.txt\", \"w\") as file:\n",
    "    for link in all_product_urls: \n",
    "        file.write(link+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of urls saved: 2894\n"
     ]
    }
   ],
   "source": [
    "#see the number of pages were extracted\n",
    "saved_sku_pages = get_products_saved(folder_path='./skincare_products')\n",
    "print(\"Number of urls saved:\", len(saved_sku_pages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each product link, save the webpage\n",
    "save_html_info(text_file =\"Sephora_URL.txt\", saved_sku_pages=saved_sku_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the product information from all the webpages\n",
    "skincare_info_dict, no_page_lst = get_skincare_info(folder = \"skincare_products\", headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert product info to csv\n",
    "all_products_df = pd.DataFrame.from_dict(skincare_info_dict).transpose()\n",
    "all_products_df.to_csv('SephoraSkincareData_v2.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products with extracted info:  2560\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of products with extracted info: \", len(all_products_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of urls in which data extraction failed:  317\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of urls in which data extraction failed: \", len(no_page_lst)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
